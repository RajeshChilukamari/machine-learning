{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl, math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, model_selection, svm\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = quandl.get('WIKI/GOOGL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ex-Dividend</th>\n",
       "      <th>Split Ratio</th>\n",
       "      <th>Adj. Open</th>\n",
       "      <th>Adj. High</th>\n",
       "      <th>Adj. Low</th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>Adj. Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-08-19</th>\n",
       "      <td>100.01</td>\n",
       "      <td>104.06</td>\n",
       "      <td>95.96</td>\n",
       "      <td>100.335</td>\n",
       "      <td>44659000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.159839</td>\n",
       "      <td>52.191109</td>\n",
       "      <td>48.128568</td>\n",
       "      <td>50.322842</td>\n",
       "      <td>44659000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-20</th>\n",
       "      <td>101.01</td>\n",
       "      <td>109.08</td>\n",
       "      <td>100.50</td>\n",
       "      <td>108.310</td>\n",
       "      <td>22834300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.661387</td>\n",
       "      <td>54.708881</td>\n",
       "      <td>50.405597</td>\n",
       "      <td>54.322689</td>\n",
       "      <td>22834300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-23</th>\n",
       "      <td>110.76</td>\n",
       "      <td>113.48</td>\n",
       "      <td>109.05</td>\n",
       "      <td>109.400</td>\n",
       "      <td>18256100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.551482</td>\n",
       "      <td>56.915693</td>\n",
       "      <td>54.693835</td>\n",
       "      <td>54.869377</td>\n",
       "      <td>18256100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-24</th>\n",
       "      <td>111.24</td>\n",
       "      <td>111.60</td>\n",
       "      <td>103.57</td>\n",
       "      <td>104.870</td>\n",
       "      <td>15247300.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.792225</td>\n",
       "      <td>55.972783</td>\n",
       "      <td>51.945350</td>\n",
       "      <td>52.597363</td>\n",
       "      <td>15247300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-25</th>\n",
       "      <td>104.76</td>\n",
       "      <td>108.00</td>\n",
       "      <td>103.88</td>\n",
       "      <td>106.000</td>\n",
       "      <td>9188600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.542193</td>\n",
       "      <td>54.167209</td>\n",
       "      <td>52.100830</td>\n",
       "      <td>53.164113</td>\n",
       "      <td>9188600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open    High     Low    Close      Volume  Ex-Dividend  \\\n",
       "Date                                                                   \n",
       "2004-08-19  100.01  104.06   95.96  100.335  44659000.0          0.0   \n",
       "2004-08-20  101.01  109.08  100.50  108.310  22834300.0          0.0   \n",
       "2004-08-23  110.76  113.48  109.05  109.400  18256100.0          0.0   \n",
       "2004-08-24  111.24  111.60  103.57  104.870  15247300.0          0.0   \n",
       "2004-08-25  104.76  108.00  103.88  106.000   9188600.0          0.0   \n",
       "\n",
       "            Split Ratio  Adj. Open  Adj. High   Adj. Low  Adj. Close  \\\n",
       "Date                                                                   \n",
       "2004-08-19          1.0  50.159839  52.191109  48.128568   50.322842   \n",
       "2004-08-20          1.0  50.661387  54.708881  50.405597   54.322689   \n",
       "2004-08-23          1.0  55.551482  56.915693  54.693835   54.869377   \n",
       "2004-08-24          1.0  55.792225  55.972783  51.945350   52.597363   \n",
       "2004-08-25          1.0  52.542193  54.167209  52.100830   53.164113   \n",
       "\n",
       "            Adj. Volume  \n",
       "Date                     \n",
       "2004-08-19   44659000.0  \n",
       "2004-08-20   22834300.0  \n",
       "2004-08-23   18256100.0  \n",
       "2004-08-24   15247300.0  \n",
       "2004-08-25    9188600.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3424, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df[['Adj. Open','Adj. High','Adj. Low','Adj. Close','Adj. Volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj. Open</th>\n",
       "      <th>Adj. High</th>\n",
       "      <th>Adj. Low</th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>Adj. Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-21</th>\n",
       "      <td>1092.57</td>\n",
       "      <td>1108.70</td>\n",
       "      <td>1087.21</td>\n",
       "      <td>1094.00</td>\n",
       "      <td>1990515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-22</th>\n",
       "      <td>1080.01</td>\n",
       "      <td>1083.92</td>\n",
       "      <td>1049.64</td>\n",
       "      <td>1053.15</td>\n",
       "      <td>3418154.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-23</th>\n",
       "      <td>1051.37</td>\n",
       "      <td>1066.78</td>\n",
       "      <td>1024.87</td>\n",
       "      <td>1026.55</td>\n",
       "      <td>2413517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-26</th>\n",
       "      <td>1050.60</td>\n",
       "      <td>1059.27</td>\n",
       "      <td>1010.58</td>\n",
       "      <td>1054.09</td>\n",
       "      <td>3272409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-27</th>\n",
       "      <td>1063.90</td>\n",
       "      <td>1064.54</td>\n",
       "      <td>997.62</td>\n",
       "      <td>1006.94</td>\n",
       "      <td>2940957.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj. Open  Adj. High  Adj. Low  Adj. Close  Adj. Volume\n",
       "Date                                                               \n",
       "2018-03-21    1092.57    1108.70   1087.21     1094.00    1990515.0\n",
       "2018-03-22    1080.01    1083.92   1049.64     1053.15    3418154.0\n",
       "2018-03-23    1051.37    1066.78   1024.87     1026.55    2413517.0\n",
       "2018-03-26    1050.60    1059.27   1010.58     1054.09    3272409.0\n",
       "2018-03-27    1063.90    1064.54    997.62     1006.94    2940957.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage = (new-old)/old\n",
    "\n",
    "#high low percentage\n",
    "df['HL_PCT'] = (df['Adj. High'] - df['Adj. Close']) / df['Adj. Close'] * 100.0\n",
    "\n",
    "#percentage change\n",
    "df['PCT_Change'] = (df['Adj. Close'] - df['Adj. Open']) / df['Adj. Open'] * 100.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Adj. Close','HL_PCT','PCT_Change','Adj. Volume',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>HL_PCT</th>\n",
       "      <th>PCT_Change</th>\n",
       "      <th>Adj. Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-08-19</th>\n",
       "      <td>50.322842</td>\n",
       "      <td>3.712563</td>\n",
       "      <td>0.324968</td>\n",
       "      <td>44659000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-20</th>\n",
       "      <td>54.322689</td>\n",
       "      <td>0.710922</td>\n",
       "      <td>7.227007</td>\n",
       "      <td>22834300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-23</th>\n",
       "      <td>54.869377</td>\n",
       "      <td>3.729433</td>\n",
       "      <td>-1.227880</td>\n",
       "      <td>18256100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-24</th>\n",
       "      <td>52.597363</td>\n",
       "      <td>6.417469</td>\n",
       "      <td>-5.726357</td>\n",
       "      <td>15247300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-25</th>\n",
       "      <td>53.164113</td>\n",
       "      <td>1.886792</td>\n",
       "      <td>1.183658</td>\n",
       "      <td>9188600.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj. Close    HL_PCT  PCT_Change  Adj. Volume\n",
       "Date                                                     \n",
       "2004-08-19   50.322842  3.712563    0.324968   44659000.0\n",
       "2004-08-20   54.322689  0.710922    7.227007   22834300.0\n",
       "2004-08-23   54.869377  3.729433   -1.227880   18256100.0\n",
       "2004-08-24   52.597363  6.417469   -5.726357   15247300.0\n",
       "2004-08-25   53.164113  1.886792    1.183658    9188600.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_col = 'Adj. Close'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(-99999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_out = int(math.ceil(0.01*len(df)))   #100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2439"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df[forecast_col].shift(-forecast_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>HL_PCT</th>\n",
       "      <th>PCT_Change</th>\n",
       "      <th>Adj. Volume</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-08-19</th>\n",
       "      <td>50.322842</td>\n",
       "      <td>3.712563</td>\n",
       "      <td>0.324968</td>\n",
       "      <td>44659000.0</td>\n",
       "      <td>60.100525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-20</th>\n",
       "      <td>54.322689</td>\n",
       "      <td>0.710922</td>\n",
       "      <td>7.227007</td>\n",
       "      <td>22834300.0</td>\n",
       "      <td>59.313094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-23</th>\n",
       "      <td>54.869377</td>\n",
       "      <td>3.729433</td>\n",
       "      <td>-1.227880</td>\n",
       "      <td>18256100.0</td>\n",
       "      <td>63.626409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-24</th>\n",
       "      <td>52.597363</td>\n",
       "      <td>6.417469</td>\n",
       "      <td>-5.726357</td>\n",
       "      <td>15247300.0</td>\n",
       "      <td>65.742942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-25</th>\n",
       "      <td>53.164113</td>\n",
       "      <td>1.886792</td>\n",
       "      <td>1.183658</td>\n",
       "      <td>9188600.0</td>\n",
       "      <td>65.000651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj. Close    HL_PCT  PCT_Change  Adj. Volume      label\n",
       "Date                                                                \n",
       "2004-08-19   50.322842  3.712563    0.324968   44659000.0  60.100525\n",
       "2004-08-20   54.322689  0.710922    7.227007   22834300.0  59.313094\n",
       "2004-08-23   54.869377  3.729433   -1.227880   18256100.0  63.626409\n",
       "2004-08-24   52.597363  6.417469   -5.726357   15247300.0  65.742942\n",
       "2004-08-25   53.164113  1.886792    1.183658    9188600.0  65.000651"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adj. Close</th>\n",
       "      <th>HL_PCT</th>\n",
       "      <th>PCT_Change</th>\n",
       "      <th>Adj. Volume</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-08-19</th>\n",
       "      <td>50.322842</td>\n",
       "      <td>3.712563</td>\n",
       "      <td>0.324968</td>\n",
       "      <td>44659000.0</td>\n",
       "      <td>60.100525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-20</th>\n",
       "      <td>54.322689</td>\n",
       "      <td>0.710922</td>\n",
       "      <td>7.227007</td>\n",
       "      <td>22834300.0</td>\n",
       "      <td>59.313094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-23</th>\n",
       "      <td>54.869377</td>\n",
       "      <td>3.729433</td>\n",
       "      <td>-1.227880</td>\n",
       "      <td>18256100.0</td>\n",
       "      <td>63.626409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-24</th>\n",
       "      <td>52.597363</td>\n",
       "      <td>6.417469</td>\n",
       "      <td>-5.726357</td>\n",
       "      <td>15247300.0</td>\n",
       "      <td>65.742942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-08-25</th>\n",
       "      <td>53.164113</td>\n",
       "      <td>1.886792</td>\n",
       "      <td>1.183658</td>\n",
       "      <td>9188600.0</td>\n",
       "      <td>65.000651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Adj. Close    HL_PCT  PCT_Change  Adj. Volume      label\n",
       "Date                                                                \n",
       "2004-08-19   50.322842  3.712563    0.324968   44659000.0  60.100525\n",
       "2004-08-20   54.322689  0.710922    7.227007   22834300.0  59.313094\n",
       "2004-08-23   54.869377  3.729433   -1.227880   18256100.0  63.626409\n",
       "2004-08-24   52.597363  6.417469   -5.726357   15247300.0  65.742942\n",
       "2004-08-25   53.164113  1.886792    1.183658    9188600.0  65.000651"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2414, 4)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features\n",
    "X= np.array(df.drop(['label'],1))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.31641125e+01,  1.88679245e+00,  1.18365788e+00,\n",
       "         9.18860000e+06],\n",
       "       [ 5.41220696e+01,  3.70679270e-02,  2.82039066e+00,\n",
       "         7.09480000e+06],\n",
       "       [ 5.32393448e+01,  2.32689590e+00, -1.80388529e+00,\n",
       "         6.21170000e+06],\n",
       "       ...,\n",
       "       [ 6.01481716e+02,  1.06233062e+00, -1.03564945e+00,\n",
       "         3.22250000e+06],\n",
       "       [ 6.00433481e+02,  1.03996124e+00, -2.32509688e-01,\n",
       "         3.36600000e+06],\n",
       "       [ 5.93351620e+02,  2.24759940e+00, -1.92902322e+00,\n",
       "         6.41050000e+06]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.01320046,  0.58796301,  0.73293079, -0.12388243],\n",
       "       [-2.00411462, -0.92512438,  1.73020551, -0.36450439],\n",
       "       [-2.01248691,  0.94797066, -1.08740379, -0.46599129],\n",
       "       ...,\n",
       "       [ 3.18736846, -0.08645244, -0.61931138, -0.80951367],\n",
       "       [ 3.17742637, -0.10475075, -0.12995174, -0.79302248],\n",
       "       [ 3.1102578 ,  0.88310558, -1.16365136, -0.44314496]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= preprocessing.scale(X)\n",
    "X[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2414,)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labels\n",
    "y=np.array(df['label'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1931, 4) (1931,)\n",
      "(483, 4) (483,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385717961757716"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Linear Regression\n",
    "clf = LinearRegression(n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "accuracy = clf.score(X_test,y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LinearRegression in module sklearn.linear_model.base:\n",
      "\n",
      "class LinearRegression(LinearModel, sklearn.base.RegressorMixin)\n",
      " |  LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
      " |  \n",
      " |  Ordinary least squares Linear Regression.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  fit_intercept : boolean, optional, default True\n",
      " |      whether to calculate the intercept for this model. If set\n",
      " |      to False, no intercept will be used in calculations\n",
      " |      (e.g. data is expected to be already centered).\n",
      " |  \n",
      " |  normalize : boolean, optional, default False\n",
      " |      This parameter is ignored when ``fit_intercept`` is set to False.\n",
      " |      If True, the regressors X will be normalized before regression by\n",
      " |      subtracting the mean and dividing by the l2-norm.\n",
      " |      If you wish to standardize, please use\n",
      " |      :class:`sklearn.preprocessing.StandardScaler` before calling ``fit`` on\n",
      " |      an estimator with ``normalize=False``.\n",
      " |  \n",
      " |  copy_X : boolean, optional, default True\n",
      " |      If True, X will be copied; else, it may be overwritten.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      The number of jobs to use for the computation. This will only provide\n",
      " |      speedup for n_targets > 1 and sufficient large problems.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : array, shape (n_features, ) or (n_targets, n_features)\n",
      " |      Estimated coefficients for the linear regression problem.\n",
      " |      If multiple targets are passed during the fit (y 2D), this\n",
      " |      is a 2D array of shape (n_targets, n_features), while if only\n",
      " |      one target is passed, this is a 1D array of length n_features.\n",
      " |  \n",
      " |  intercept_ : array\n",
      " |      Independent term in the linear model.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.linear_model import LinearRegression\n",
      " |  >>> X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
      " |  >>> # y = 1 * x_0 + 2 * x_1 + 3\n",
      " |  >>> y = np.dot(X, np.array([1, 2])) + 3\n",
      " |  >>> reg = LinearRegression().fit(X, y)\n",
      " |  >>> reg.score(X, y)\n",
      " |  1.0\n",
      " |  >>> reg.coef_\n",
      " |  array([1., 2.])\n",
      " |  >>> reg.intercept_ # doctest: +ELLIPSIS\n",
      " |  3.0000...\n",
      " |  >>> reg.predict(np.array([[3, 5]]))\n",
      " |  array([16.])\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  From the implementation point of view, this is just plain Ordinary\n",
      " |  Least Squares (scipy.linalg.lstsq) wrapped as a predictor object.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LinearRegression\n",
      " |      LinearModel\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit linear model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Training data\n",
      " |      \n",
      " |      y : array_like, shape (n_samples, n_targets)\n",
      " |          Target values. Will be cast to X's dtype if necessary\n",
      " |      \n",
      " |      sample_weight : numpy array of shape [n_samples]\n",
      " |          Individual weights for each sample\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             parameter *sample_weight* support to LinearRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : returns an instance of self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from LinearModel:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict using the linear model\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape (n_samples,)\n",
      " |          Returns predicted values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix instead, shape = (n_samples,\n",
      " |          n_samples_fitted], where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(LinearRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9382111348937929"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Support Vector Machine - Regression\n",
    "clf = svm.SVR(gamma='scale',kernel='poly')\n",
    "clf.fit(X_train, y_train )\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SVR in module sklearn.svm.classes:\n",
      "\n",
      "class SVR(sklearn.svm.base.BaseLibSVM, sklearn.base.RegressorMixin)\n",
      " |  SVR(kernel='rbf', degree=3, gamma='auto_deprecated', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
      " |  \n",
      " |  Epsilon-Support Vector Regression.\n",
      " |  \n",
      " |  The free parameters in the model are C and epsilon.\n",
      " |  \n",
      " |  The implementation is based on libsvm.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <svm_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  kernel : string, optional (default='rbf')\n",
      " |       Specifies the kernel type to be used in the algorithm.\n",
      " |       It must be one of 'linear', 'poly', 'rbf', 'sigmoid', 'precomputed' or\n",
      " |       a callable.\n",
      " |       If none is given, 'rbf' will be used. If a callable is given it is\n",
      " |       used to precompute the kernel matrix.\n",
      " |  \n",
      " |  degree : int, optional (default=3)\n",
      " |      Degree of the polynomial kernel function ('poly').\n",
      " |      Ignored by all other kernels.\n",
      " |  \n",
      " |  gamma : float, optional (default='auto')\n",
      " |      Kernel coefficient for 'rbf', 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |      Current default is 'auto' which uses 1 / n_features,\n",
      " |      if ``gamma='scale'`` is passed then it uses 1 / (n_features * X.var())\n",
      " |      as value of gamma. The current default of gamma, 'auto', will change\n",
      " |      to 'scale' in version 0.22. 'auto_deprecated', a deprecated version of\n",
      " |      'auto' is used as a default indicating that no explicit value of gamma\n",
      " |      was passed.\n",
      " |  \n",
      " |  coef0 : float, optional (default=0.0)\n",
      " |      Independent term in kernel function.\n",
      " |      It is only significant in 'poly' and 'sigmoid'.\n",
      " |  \n",
      " |  tol : float, optional (default=1e-3)\n",
      " |      Tolerance for stopping criterion.\n",
      " |  \n",
      " |  C : float, optional (default=1.0)\n",
      " |      Penalty parameter C of the error term.\n",
      " |  \n",
      " |  epsilon : float, optional (default=0.1)\n",
      " |       Epsilon in the epsilon-SVR model. It specifies the epsilon-tube\n",
      " |       within which no penalty is associated in the training loss function\n",
      " |       with points predicted within a distance epsilon from the actual\n",
      " |       value.\n",
      " |  \n",
      " |  shrinking : boolean, optional (default=True)\n",
      " |      Whether to use the shrinking heuristic.\n",
      " |  \n",
      " |  cache_size : float, optional\n",
      " |      Specify the size of the kernel cache (in MB).\n",
      " |  \n",
      " |  verbose : bool, default: False\n",
      " |      Enable verbose output. Note that this setting takes advantage of a\n",
      " |      per-process runtime setting in libsvm that, if enabled, may not work\n",
      " |      properly in a multithreaded context.\n",
      " |  \n",
      " |  max_iter : int, optional (default=-1)\n",
      " |      Hard limit on iterations within solver, or -1 for no limit.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  support_ : array-like, shape = [n_SV]\n",
      " |      Indices of support vectors.\n",
      " |  \n",
      " |  support_vectors_ : array-like, shape = [nSV, n_features]\n",
      " |      Support vectors.\n",
      " |  \n",
      " |  dual_coef_ : array, shape = [1, n_SV]\n",
      " |      Coefficients of the support vector in the decision function.\n",
      " |  \n",
      " |  coef_ : array, shape = [1, n_features]\n",
      " |      Weights assigned to the features (coefficients in the primal\n",
      " |      problem). This is only available in the case of a linear kernel.\n",
      " |  \n",
      " |      `coef_` is readonly property derived from `dual_coef_` and\n",
      " |      `support_vectors_`.\n",
      " |  \n",
      " |  intercept_ : array, shape = [1]\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.svm import SVR\n",
      " |  >>> import numpy as np\n",
      " |  >>> n_samples, n_features = 10, 5\n",
      " |  >>> np.random.seed(0)\n",
      " |  >>> y = np.random.randn(n_samples)\n",
      " |  >>> X = np.random.randn(n_samples, n_features)\n",
      " |  >>> clf = SVR(gamma='scale', C=1.0, epsilon=0.2)\n",
      " |  >>> clf.fit(X, y) #doctest: +NORMALIZE_WHITESPACE\n",
      " |  SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='scale',\n",
      " |      kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  NuSVR\n",
      " |      Support Vector Machine for regression implemented using libsvm\n",
      " |      using a parameter to control the number of support vectors.\n",
      " |  \n",
      " |  LinearSVR\n",
      " |      Scalable Linear Support Vector Machine for regression\n",
      " |      implemented using liblinear.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  **References:**\n",
      " |  `LIBSVM: A Library for Support Vector Machines\n",
      " |  <http://www.csie.ntu.edu.tw/~cjlin/papers/libsvm.pdf>`__\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SVR\n",
      " |      sklearn.svm.base.BaseLibSVM\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.RegressorMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, kernel='rbf', degree=3, gamma='auto_deprecated', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.svm.base.BaseLibSVM:\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the SVM model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples, n_samples).\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values (class labels in classification, real numbers in\n",
      " |          regression)\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,)\n",
      " |          Per-sample weights. Rescale C per sample. Higher weights\n",
      " |          force the classifier to put more emphasis on these points.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |      \n",
      " |      Notes\n",
      " |      ------\n",
      " |      If X and y are not C-ordered and contiguous arrays of np.float64 and\n",
      " |      X is not a scipy.sparse.csr_matrix, X and/or y may be copied.\n",
      " |      \n",
      " |      If X is a dense array, then the other methods will not support sparse\n",
      " |      matrices as input.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform regression on samples in X.\n",
      " |      \n",
      " |      For an one-class model, +1 (inlier) or -1 (outlier) is returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          For kernel=\"precomputed\", the expected shape of X is\n",
      " |          (n_samples_test, n_samples_train).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y_pred : array, shape (n_samples,)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.svm.base.BaseLibSVM:\n",
      " |  \n",
      " |  coef_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.RegressorMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the coefficient of determination R^2 of the prediction.\n",
      " |      \n",
      " |      The coefficient R^2 is defined as (1 - u/v), where u is the residual\n",
      " |      sum of squares ((y_true - y_pred) ** 2).sum() and v is the total\n",
      " |      sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
      " |      The best possible score is 1.0 and it can be negative (because the\n",
      " |      model can be arbitrarily worse). A constant model that always\n",
      " |      predicts the expected value of y, disregarding the input features,\n",
      " |      would get a R^2 score of 0.0.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples. For some estimators this may be a\n",
      " |          precomputed kernel matrix instead, shape = (n_samples,\n",
      " |          n_samples_fitted], where n_samples_fitted is the number of\n",
      " |          samples used in the fitting for the estimator.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True values for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          R^2 of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(svm.SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2004-08-24 00:00:00')"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[3].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on _iLocIndexer in module pandas.core.indexing object:\n",
      "\n",
      "class _iLocIndexer(_LocationIndexer)\n",
      " |  Purely integer-location based indexing for selection by position.\n",
      " |  \n",
      " |  ``.iloc[]`` is primarily integer position based (from ``0`` to\n",
      " |  ``length-1`` of the axis), but may also be used with a boolean\n",
      " |  array.\n",
      " |  \n",
      " |  Allowed inputs are:\n",
      " |  \n",
      " |  - An integer, e.g. ``5``.\n",
      " |  - A list or array of integers, e.g. ``[4, 3, 0]``.\n",
      " |  - A slice object with ints, e.g. ``1:7``.\n",
      " |  - A boolean array.\n",
      " |  - A ``callable`` function with one argument (the calling Series, DataFrame\n",
      " |    or Panel) and that returns valid output for indexing (one of the above).\n",
      " |    This is useful in method chains, when you don't have a reference to the\n",
      " |    calling object, but would like to base your selection on some value.\n",
      " |  \n",
      " |  ``.iloc`` will raise ``IndexError`` if a requested indexer is\n",
      " |  out-of-bounds, except *slice* indexers which allow out-of-bounds\n",
      " |  indexing (this conforms with python/numpy *slice* semantics).\n",
      " |  \n",
      " |  See more at ref:`Selection by Position <indexing.integer>`.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DataFrame.iat : Fast integer location scalar accessor.\n",
      " |  DataFrame.loc : Purely label-location based indexer for selection by label.\n",
      " |  Series.iloc : Purely integer-location based indexing for\n",
      " |                 selection by position.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
      " |  ...           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
      " |  ...           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
      " |  >>> df = pd.DataFrame(mydict)\n",
      " |  >>> df\n",
      " |        a     b     c     d\n",
      " |  0     1     2     3     4\n",
      " |  1   100   200   300   400\n",
      " |  2  1000  2000  3000  4000\n",
      " |  \n",
      " |  **Indexing just the rows**\n",
      " |  \n",
      " |  With a scalar integer.\n",
      " |  \n",
      " |  >>> type(df.iloc[0])\n",
      " |  <class 'pandas.core.series.Series'>\n",
      " |  >>> df.iloc[0]\n",
      " |  a    1\n",
      " |  b    2\n",
      " |  c    3\n",
      " |  d    4\n",
      " |  Name: 0, dtype: int64\n",
      " |  \n",
      " |  With a list of integers.\n",
      " |  \n",
      " |  >>> df.iloc[[0]]\n",
      " |     a  b  c  d\n",
      " |  0  1  2  3  4\n",
      " |  >>> type(df.iloc[[0]])\n",
      " |  <class 'pandas.core.frame.DataFrame'>\n",
      " |  \n",
      " |  >>> df.iloc[[0, 1]]\n",
      " |       a    b    c    d\n",
      " |  0    1    2    3    4\n",
      " |  1  100  200  300  400\n",
      " |  \n",
      " |  With a `slice` object.\n",
      " |  \n",
      " |  >>> df.iloc[:3]\n",
      " |        a     b     c     d\n",
      " |  0     1     2     3     4\n",
      " |  1   100   200   300   400\n",
      " |  2  1000  2000  3000  4000\n",
      " |  \n",
      " |  With a boolean mask the same length as the index.\n",
      " |  \n",
      " |  >>> df.iloc[[True, False, True]]\n",
      " |        a     b     c     d\n",
      " |  0     1     2     3     4\n",
      " |  2  1000  2000  3000  4000\n",
      " |  \n",
      " |  With a callable, useful in method chains. The `x` passed\n",
      " |  to the ``lambda`` is the DataFrame being sliced. This selects\n",
      " |  the rows whose index label even.\n",
      " |  \n",
      " |  >>> df.iloc[lambda x: x.index % 2 == 0]\n",
      " |        a     b     c     d\n",
      " |  0     1     2     3     4\n",
      " |  2  1000  2000  3000  4000\n",
      " |  \n",
      " |  **Indexing both axes**\n",
      " |  \n",
      " |  You can mix the indexer types for the index and columns. Use ``:`` to\n",
      " |  select the entire axis.\n",
      " |  \n",
      " |  With scalar integers.\n",
      " |  \n",
      " |  >>> df.iloc[0, 1]\n",
      " |  2\n",
      " |  \n",
      " |  With lists of integers.\n",
      " |  \n",
      " |  >>> df.iloc[[0, 2], [1, 3]]\n",
      " |        b     d\n",
      " |  0     2     4\n",
      " |  2  2000  4000\n",
      " |  \n",
      " |  With `slice` objects.\n",
      " |  \n",
      " |  >>> df.iloc[1:3, 0:3]\n",
      " |        a     b     c\n",
      " |  1   100   200   300\n",
      " |  2  1000  2000  3000\n",
      " |  \n",
      " |  With a boolean array whose length matches the columns.\n",
      " |  \n",
      " |  >>> df.iloc[:, [True, False, True, False]]\n",
      " |        a     c\n",
      " |  0     1     3\n",
      " |  1   100   300\n",
      " |  2  1000  3000\n",
      " |  \n",
      " |  With a callable function that expects the Series or DataFrame.\n",
      " |  \n",
      " |  >>> df.iloc[:, lambda df: [0, 2]]\n",
      " |        a     c\n",
      " |  0     1     3\n",
      " |  1   100   300\n",
      " |  2  1000  3000\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      _iLocIndexer\n",
      " |      _LocationIndexer\n",
      " |      _NDFrameIndexer\n",
      " |      pandas._libs.indexing._NDFrameIndexerBase\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods inherited from _LocationIndexer:\n",
      " |  \n",
      " |  __getitem__(self, key)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  __call__(self, axis=None)\n",
      " |      Call self as a function.\n",
      " |  \n",
      " |  __iter__(self)\n",
      " |  \n",
      " |  __setitem__(self, key, value)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from _NDFrameIndexer:\n",
      " |  \n",
      " |  axis = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pandas._libs.indexing._NDFrameIndexerBase:\n",
      " |  \n",
      " |  __init__(self, /, *args, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __reduce__ = __reduce_cython__(...)\n",
      " |  \n",
      " |  __setstate__ = __setstate_cython__(...)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods inherited from pandas._libs.indexing._NDFrameIndexerBase:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pandas._libs.indexing._NDFrameIndexerBase:\n",
      " |  \n",
      " |  name\n",
      " |  \n",
      " |  ndim\n",
      " |  \n",
      " |  obj\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(df.iloc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
